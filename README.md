# Enhancing Retrieval-Augmented Generation with Adaptive Chunking 
Contributors: Tanish Upreti, Zihan Gong, Wenlong Zheng, Axel Tang

## An Applied Deep Learning Project
Tech Used: 
```ruby
Concepts:
  - RAG
  - LLM
  - Adaptive Chunking
Tech:
  - Python
  - LLaMA-2, LLama-3, Mixtral
  - FAISS, ColBERT
```

## A Core Summary 
Retrieval-Augmented Generation (RAG) - A framework that combines information retrieval (fetching relevant documents) with large language models (LLMs) â€” by introducing adaptive chunking which is a smarter way of splitting text into pieces for retrieval.

Adaptive chunking makes RAG systems more intelligent by tailoring how text is divided, leading to better retrieval quality, stronger context understanding, and higher fidelity AI responses.

## Requirements of the Project
1. Implement a Retrieval-Augmented Generation pipeline using fixed-size chunking strategy as
baseline
2. Implement different adaptive chunking strategies to Retrieval-AugmentedGeneration
3. Use TriviaQA, NaturalQuestions to compare and analyze the impact of different chunking strategies
4. Deliver source code for implementation of different chunking strategies, and results
of each

## Setup
##-----##
